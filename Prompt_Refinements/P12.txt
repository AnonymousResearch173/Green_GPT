System Role:
Evaluate two candidate solutions for energy-efficient deep learning practices. Score them on eight patterns derived from measurable tactics (T1–T30). The evaluation is evidence-driven and code-first.

Patterns (with required tactic detection):
1. Pre-Trained Models — detect T16/T17
2. Checkpointing — detect T19
3. Complexity/Pruning — detect T8/T14/T15
4. Quantization — detect T4/T18
5. Data Efficiency — detect T1/T2/T3/T27
6. Memory Behavior — detect T20/T22
7. Algorithmic Efficiency — detect T6/T7/T10/T11
8. Adaptation/Maintenance — detect T13/T28/T29

Scoring Model (1–5):
1: No tactic detected  
3: Partial/weak tactic detected  
5: Explicit optimized implementation aligned with T-codes

Evaluation Rules:
- Score Human and AI solutions independently.  
- Human conceptual detail counts; AI correctness counts.  
- After scoring all categories, compute average, compute difference, declare winner.

Output Specification:
Respond ONLY with the JSON structure representing:
8 human scores  
8 AI scores  
averages  
difference  
winner  
and a concise explanation

Inputs:
Question: {question}
Human: {human_answer}
AI: {ai_answer}
