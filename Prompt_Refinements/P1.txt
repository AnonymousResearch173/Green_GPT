prompt_template = """
Objective:
Execute a standardized evaluation protocol to judge the energy-efficiency merit of Human vs AI solutions across eight independently scored patterns.
Protocol Summary:
Each pattern corresponds to a defined optimization domain. You must assign a score between 1 and 5 to both solutions per pattern, based exclusively on observable evidence in implementation or explanation.
Scoring Key:
1 = Not demonstrated  
2 = Minimal demonstration  
3 = Adequate, meets baseline  
4 = Strong, well-applied  
5 = Ideal, maximally energy-efficient


Optimization Domains:
Pre-trained Model Domain  
Tactic: TL, KD, pretrained checkpoints.
Checkpoint Domain  
Tactic: save/restore integration, fault tolerance.
Model Optimization Domain  
Tactic: pruning, simplification, sparsity handling.
Quantization Domain  
Tactic: int8/FP16 conversions, QAT routines.
Data Efficiency Domain  
Tactic: sampling, deduplication, lightweight preprocessing.
Memory Efficiency Domain  
Tactic: layout control, on-device policies, workload partitioning.
Computation Optimization Domain  
Tactic: optimized instructions, vectorization, adaptive logic.
Adaptation & Maintenance Domain  
Tactic: graph rewrites, dynamic updates, selective retraining.


Protocol Rules:
Evaluate all patterns independently.
Prioritize concrete code over abstract claims.
Humans may receive significant credit for expert conceptual clarity.
AI must display practical, implementable guidance.
Identify which tactic are supported.
Compute Human and AI averages.
Winner = higher average.
Ties:
allowed only if averages equal OR
difference â‰¤ 0.25 AND both solutions offer equally strong but different strengths.
Return Format:
ONLY return the JSON structure below:
{
"human_pattern_1_score": ...,
...
"ai_pattern_8_score": ...,
"human_average_score": "...",
"ai_average_score": "...",
"score_difference": "...",
"winner": "...",
"analysis_explanation": "..."
}
Inputs:
{question}
{human_answer}
{ai_answer}
"""
