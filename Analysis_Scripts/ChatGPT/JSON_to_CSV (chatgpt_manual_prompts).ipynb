{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6ey-63a1jmf",
        "outputId": "38f91052-7b7e-4e46-8f04-eb35ba4cf42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV file successfully created: evaluation.csv\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "# ✅ paste your JSON object here between triple quotes\n",
        "json_string = \"\"\"\n",
        "{\n",
        "  \"human_pattern_1_score\": 1,\n",
        "  \"human_pattern_2_score\": 1,\n",
        "  \"human_pattern_3_score\": 1,\n",
        "  \"human_pattern_4_score\": 1,\n",
        "  \"human_pattern_5_score\": 1,\n",
        "  \"human_pattern_6_score\": 5,\n",
        "  \"human_pattern_7_score\": 4,\n",
        "  \"human_pattern_8_score\": 3,\n",
        "  \"ai_pattern_1_score\": 1,\n",
        "  \"ai_pattern_2_score\": 1,\n",
        "  \"ai_pattern_3_score\": 1,\n",
        "  \"ai_pattern_4_score\": 1,\n",
        "  \"ai_pattern_5_score\": 1,\n",
        "  \"ai_pattern_6_score\": 5,\n",
        "  \"ai_pattern_7_score\": 5,\n",
        "  \"ai_pattern_8_score\": 4,\n",
        "  \"human_average_score\": 2.125,\n",
        "  \"ai_average_score\": 2.375,\n",
        "  \"score_difference\": 0.25,\n",
        "  \"winner\": \"AI\",\n",
        "  \"analysis_explanation\": \"Human excels in Memory Management (5) with deep TensorFlow internals analysis using objgraph to identify graph object retention. AI dominates Algorithm Optimization (5) with comprehensive code solutions like clear_session() and PyGILState management, plus superior Model Maintenance (4) with practical session cleanup strategies. Both identify the core TensorFlow graph accumulation issue, but AI provides actionable implementations while Human offers expert debugging insights.\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# ✅ parse JSON string\n",
        "data = json.loads(json_string)\n",
        "\n",
        "# ✅ ensure data is a list of dicts\n",
        "if isinstance(data, dict):\n",
        "    data = [data]\n",
        "\n",
        "# ✅ write CSV\n",
        "with open(\"evaluation.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=data[0].keys())\n",
        "    writer.writeheader()\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(\"✅ CSV file successfully created: evaluation.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# === Step 1: Load your main CSV ===\n",
        "input_csv = \"/content/DL_Energy_Patterns with JSON.csv\"\n",
        "output_csv = \"expanded_data.csv\"\n",
        "\n",
        "\n",
        "# === Step 2: Try reading CSV with multiple encodings ===\n",
        "encodings_to_try = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"ISO-8859-1\"]\n",
        "\n",
        "for enc in encodings_to_try:\n",
        "    try:\n",
        "        df = pd.read_csv(input_csv, encoding=enc)\n",
        "        print(f\"✅ Successfully read CSV using encoding: {enc}\")\n",
        "        break\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"❌ Failed with encoding: {enc}\")\n",
        "else:\n",
        "    raise ValueError(\"Could not read CSV with any known encoding!\")\n",
        "\n",
        "# === Step 3: Parse JSON in a specific column ===\n",
        "# Replace 'json_column' with the actual column name where you paste the JSON text\n",
        "json_col = \"JSON\"\n",
        "\n",
        "# Create a DataFrame from parsed JSON\n",
        "def parse_json_safe(j):\n",
        "    try:\n",
        "        return json.loads(j)\n",
        "    except (json.JSONDecodeError, TypeError):\n",
        "        return {}\n",
        "\n",
        "json_expanded = df[json_col].apply(parse_json_safe).apply(pd.Series)\n",
        "\n",
        "# === Step 4: Combine with the original columns you want to keep ===\n",
        "# Adjust these names based on your CSV structure\n",
        "columns_to_keep = [\"PostId\", \"QUESTION\", \"CHATGPT_ANSWER\", \"SO_ANSWER\"]\n",
        "\n",
        "final_df = pd.concat([df[columns_to_keep], json_expanded], axis=1)\n",
        "\n",
        "# === Step 5: Save to CSV ===\n",
        "final_df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(f\"\\n✅ Expanded CSV successfully saved to: {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qkmIkCs4dXq",
        "outputId": "f962c8b4-6140-4d53-93e8-4853c155e961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Failed with encoding: utf-8\n",
            "❌ Failed with encoding: utf-8-sig\n",
            "❌ Failed with encoding: cp1252\n",
            "✅ Successfully read CSV using encoding: ISO-8859-1\n",
            "\n",
            "✅ Expanded CSV successfully saved to: expanded_data.csv\n"
          ]
        }
      ]
    }
  ]
}